{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f42a3ce",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Introduction to Machine Learning - 25737-2</h1>\n",
    "<h4 align=\"center\">Dr. R. Amiri</h4>\n",
    "<h4 align=\"center\">Sharif University of Technology, Spring 2024</h4>\n",
    "\n",
    "\n",
    "**<font color='red'>Plagiarism is strongly prohibited!</font>**\n",
    "\n",
    "\n",
    "**Student Name**:Omid Keshavarz\n",
    "\n",
    "**Student ID**:99102361\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01c559e",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "First we import libraries that we need for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0423187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import any other libraries needed below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f795731",
   "metadata": {},
   "source": [
    "## Reading Data and Preprocessing\n",
    "\n",
    "In this section, we want to read data from a CSV file and then preprocess it to make it ready for the rest of the problem.\n",
    "\n",
    "First, we read the data in the cell below and extract an $m \\times n$ matrix, $X$, and an $m \\times 1$ vector, $Y$, from it, which represent our knowledge about the features of the data (`X1`, `X2`, `X3`) and the class (`Y`), respectively. Note that by $m$, we mean the number of data points and by $n$, we mean the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410e750d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from the CSV file\n",
    "data = pd.read_csv('./Q3/data_logistic.csv')\n",
    "\n",
    "# Extract features and labels\n",
    "X = data[['X1', 'X2', 'X3']].values\n",
    "Y = data['Y'].values.reshape(-1, 1)\n",
    "\n",
    "# Print the shapes of X and Y\n",
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866734e2",
   "metadata": {},
   "source": [
    "Next, we should normalize our data. For normalizing a vector $\\mathbf{x}$, a very common method is to use this formula:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{norm} = \\dfrac{\\mathbf{x} - \\overline{\\mathbf{x}}}{\\sigma_\\mathbf{x}}\n",
    "$$\n",
    "\n",
    "Here, $\\overline{x}$ and $\\sigma_\\mathbf{x}$ denote the mean and standard deviation of vector $\\mathbf{x}$, respectively. Use this formula and store the new $X$ and $Y$ vectors in the cell below.\n",
    "\n",
    "**Question**: Briefly explain why we need to normalize our data before starting the training.\n",
    "\n",
    "**Answer**:\n",
    "Normalizing data is a crucial preprocessing step before training machine learning models for several reasons:\n",
    "\n",
    "Scale Independence: Features often have different scales. For example, one feature might range from 0 to 1, while another might range from 0 to 1000. If we don't normalize these features, the model might give undue importance to features with larger scales, leading to suboptimal performance.\n",
    "Faster Convergence: Normalizing data can help algorithms converge more quickly during training. Many optimization algorithms, such as gradient descent, work more efficiently when features are on similar scales. Normalizing the data can help prevent oscillation and slow convergence.\n",
    "Improved Numerical Stability: Normalizing data can improve the numerical stability of the optimization process. Large input values can lead to large intermediate values in computations, which may cause numerical overflow or underflow issues. Normalizing data to a similar scale helps mitigate these problems.\n",
    "Regularization: Some regularization techniques, such as L1 and L2 regularization, assume that features are on similar scales. Normalizing the data ensures that regularization penalties are applied fairly across all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e757eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate mean and standard deviation for each feature\n",
    "X_mean = np.mean(X, axis=0)\n",
    "X_std = np.std(X, axis=0)\n",
    "\n",
    "# Normalize features\n",
    "X_normalized = (X - X_mean) / X_std\n",
    "\n",
    "# Calculate mean and standard deviation for labels\n",
    "Y_mean = np.mean(Y)\n",
    "Y_std = np.std(Y)\n",
    "\n",
    "# Normalize labels\n",
    "Y_normalized = (Y - Y_mean) / Y_std\n",
    "\n",
    "# Print the shapes of X_normalized and Y_normalized\n",
    "print(X_normalized.shape)\n",
    "print(Y_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465bfa4",
   "metadata": {},
   "source": [
    "Finally, we should add a column of $1$s at the beginning of $X$ to represent the bias term. Do this in the next cell. Note that after this process, $X$ should be an $m \\times (n+1)$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a60f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Add a column of ones to represent the bias term\n",
    "X = np.insert(X_normalized, 0, 1, axis=1)\n",
    "\n",
    "# Print the shape of X\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf0d78",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8714abe",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "You should begin by implementing the $\\sigma(\\mathbf{x})$ function. Recall that the logistic regression hypothesis $\\mathcal{h}()$ is defined as:\n",
    "$$\n",
    "\\mathcal{h}_{\\theta}(\\mathbf{x}) = \\mathcal{g}(\\theta^\\mathbf{T}\\mathbf{x})\n",
    "$$\n",
    "where $\\mathcal{g}()$ is the sigmoid function as:\n",
    "$$\n",
    "\\mathcal{g}(\\mathbf{z}) = \\frac{1}{1+exp^{-\\mathbf{z}}}\n",
    "$$\n",
    "The Sigmoid function has the property that $\\mathbf{g}(+\\infty)\\approx 1$ and $\\mathcal{g}(âˆ’\\infty)\\approx0$. Test your function by calling `sigmoid(z)` on different test samples. Be certain that your sigmoid function works with both vectors and matrices - for either a vector or a matrix, your function should perform the sigmoid function on every element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6b6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(Z):\n",
    "    '''\n",
    "    Applies the sigmoid function on every element of Z\n",
    "    Arguments:\n",
    "        Z can be a (n,) vector or (n , m) matrix\n",
    "    Returns:\n",
    "        A vector/matrix, same shape with Z, that has the sigmoid function applied elementwise\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-Z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83846074",
   "metadata": {},
   "source": [
    "### Cost Function \n",
    "Implement the functions to compute the cost function. Recall the cost function for logistic regression is a scalar value given by:\n",
    "$$\n",
    "\\mathcal{J}(\\theta) = \\sum_{i=1}^{n}[-y^{(i)}\\log{(\\mathcal{h}_\\theta(\\mathbf{x}^{(i)}))}-(1-y^{(i)})\\log{(1-\\mathcal{h}_\\theta(\\mathbf{x}^{(i)}))}] + \\frac{\\lambda}{2}||\\theta||_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a9bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(theta, X, y, regLambda):\n",
    "    '''\n",
    "    Computes the objective function\n",
    "    Arguments:\n",
    "        theta is d-dimensional numpy vector\n",
    "        X is a n-by-d numpy matrix\n",
    "        y is an n-dimensional numpy vector\n",
    "        regLambda is the scalar regularization constant\n",
    "    Returns:\n",
    "        a scalar value of the cost  ** make certain you're not returning a 1 x 1 matrix! **\n",
    "    '''\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    loss = -np.mean(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    reg_term = regLambda / (2 * m) * np.sum(theta[1:]**2)  # Regularization term excluding bias term\n",
    "    return loss + reg_term\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf1146",
   "metadata": {},
   "source": [
    "### Gradient of the Cost Function\n",
    "Now, we want to calculate the gradient of the cost function. The gradient of the cost function is a d-dimensional vector.\\\n",
    "We must be careful not to regularize the $\\theta_0$ parameter (corresponding to the first feature we add to each instance), and so the 0's element is given by:\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{J}(\\theta)}{\\partial \\theta_0} = \\sum_{i=1}^n (\\mathcal{h}_\\theta(\\mathbf{x}^{(i)})-y^{(i)})\n",
    "$$\n",
    "\n",
    "Question: What is the answer to this problem for the $j^{th}$ element (for $j=1...d$)?\n",
    "\n",
    "Answer:\n",
    "\n",
    "\n",
    "For the $j^{th}$ element of the gradient of the cost function with respect to $\\theta$, the expression is derived from the general gradient formula for logistic regression, with the additional consideration of regularization.\n",
    "\n",
    "The general formula for the gradient of the cost function with respect to $\\theta_j$ (for $j = 1, 2, \\ldots, d$) is:\n",
    "$$\n",
    "\n",
    "\\frac{\\partial \\mathcal{J}(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} (\\mathcal{h}_\\theta(\\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)} + \\frac{\\lambda}{m} \\theta_j\n",
    "\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "This equation comprises two terms:\n",
    "\n",
    "The derivative of the loss function with respect to $\\theta_j$, which represents the contribution of the $j^{th}$ feature to the error. It is computed as the average of the product of the prediction error $(\\mathcal{h}_\\theta(\\mathbf{x}^{(i)}) - y^{(i)})$ and the $j^{th}$ feature value $x_j^{(i)}$ over all training examples.\n",
    "The regularization term, which penalizes large values of $\\theta_j$. It is added to the derivative of the loss function to encourage smaller parameter values, thus preventing overfitting. This term is scaled by the regularization parameter $\\lambda$.\n",
    "However, for $j = 0$, corresponding to the bias term, the regularization is not applied, so the formula simplifies to:\n",
    "\n",
    "$$\n",
    "\n",
    "\\frac{\\partial \\mathcal{J}(\\theta)}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^{m} (\\mathcal{h}_\\theta(\\mathbf{x}^{(i)}) - y^{(i)})\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f7c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGradient(theta, X, y, regLambda):\n",
    "    '''\n",
    "    Computes the gradient of the objective function\n",
    "    Arguments:\n",
    "        theta is d-dimensional numpy vector\n",
    "        X is a n-by-d numpy matrix\n",
    "        y is an n-dimensional numpy vector\n",
    "        regLambda is the scalar regularization constant\n",
    "    Returns:\n",
    "        the gradient, a d-dimensional vector\n",
    "    '''\n",
    "    m, n = X.shape\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    error = h - y\n",
    "    grad = np.dot(X.T, error) / m\n",
    "    grad[1:] += (regLambda / m) * theta[1:]  # Regularization term excluding bias term\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bc86bd",
   "metadata": {},
   "source": [
    "### Training and Prediction\n",
    "Once you have the cost and gradient functions complete, implemen tthe fit and predict methods.\\\n",
    "Your fit method should train the model via gradient descent, relying on the cost and gradient functions. This function should return two parameters. The first parameter is $\\theta$, and the second parameter is a `numpy` array that contains the loss in each iteration. This array is indicated by `loss_history` in the code.\\\n",
    "Instead of simply running gradient descent for a specific number of iterations, we will use a more sophisticated method: we will stop it after the solution hasconverged. Stop the gradient descent procedure when $\\theta$ stops changing between consecutive iterations. You can detect this convergence when:\n",
    "$$\n",
    "||\\theta_{new}-\\theta_{old}||_2 <= \\epsilon,\n",
    "$$\n",
    "for some small $\\epsilon$ (e.g, $\\epsilon=10E-4$).\\\n",
    "For readability, weâ€™d recommend implementing this convergence test as a dedicated function `hasConverged`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc0cad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, regLambda=0.01, alpha=0.01, epsilon=1e-4, maxNumIters=100):\n",
    "    '''\n",
    "    Trains the model\n",
    "    Arguments:\n",
    "        X           is a n-by-d numpy matrix\n",
    "        y           is an n-dimensional numpy vector\n",
    "        maxNumIters is the maximum number of gradient descent iterations\n",
    "        regLambda   is the scalar regularization constant\n",
    "        epsilon     is the convergence rate\n",
    "        alpha       is the gradient descent learning rate\n",
    "    '''\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros((n, 1))  # Initialize theta to zeros\n",
    "    loss_history = []  # List to store the loss at each iteration\n",
    "    for _ in range(maxNumIters):\n",
    "        loss = computeCost(theta, X, y, regLambda)\n",
    "        grad = computeGradient(theta, X, y, regLambda)\n",
    "        theta_new = theta - alpha * grad\n",
    "        if hasConverged(theta, theta_new, epsilon):\n",
    "            break\n",
    "        theta = theta_new\n",
    "        loss_history.append(loss)\n",
    "    return theta, loss_history\n",
    "\n",
    "def hasConverged(theta_old, theta_new, epsilon):\n",
    "    '''\n",
    "    Return if the theta converged or not\n",
    "    Arguments:\n",
    "        theta_old   is the theta calculated in previous iteration\n",
    "        theta_new   is the theta calculated in current iteration\n",
    "        epsilon     is the convergence rate\n",
    "    '''\n",
    "    return np.linalg.norm(theta_new - theta_old) <= epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb648852",
   "metadata": {},
   "source": [
    "Finally, we want to evaluate our loss for this problem. Complete the cell below to calculate and print the loss of each iteration and the final theta of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "252e556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Loss = 0.6931471805599453\n",
      "Iteration 2: Loss = 0.6844231894886041\n",
      "Iteration 3: Loss = 0.6757430885565388\n",
      "Iteration 4: Loss = 0.6671066508137952\n",
      "Iteration 5: Loss = 0.6585136456832319\n",
      "Iteration 6: Loss = 0.649963839094398\n",
      "Iteration 7: Loss = 0.641456993617721\n",
      "Iteration 8: Loss = 0.6329928685988295\n",
      "Iteration 9: Loss = 0.6245712202928538\n",
      "Iteration 10: Loss = 0.6161918019985356\n",
      "Iteration 11: Loss = 0.6078543641919976\n",
      "Iteration 12: Loss = 0.599558654660019\n",
      "Iteration 13: Loss = 0.5913044186326691\n",
      "Iteration 14: Loss = 0.5830913989151598\n",
      "Iteration 15: Loss = 0.5749193360187806\n",
      "Iteration 16: Loss = 0.5667879682907841\n",
      "Iteration 17: Loss = 0.558697032043097\n",
      "Iteration 18: Loss = 0.55064626167974\n",
      "Iteration 19: Loss = 0.5426353898228389\n",
      "Iteration 20: Loss = 0.5346641474371224\n",
      "Iteration 21: Loss = 0.5267322639528039\n",
      "Iteration 22: Loss = 0.5188394673867502\n",
      "Iteration 23: Loss = 0.51098548446185\n",
      "Iteration 24: Loss = 0.5031700407244957\n",
      "Iteration 25: Loss = 0.4953928606601025\n",
      "Iteration 26: Loss = 0.4876536678065921\n",
      "Iteration 27: Loss = 0.47995218486577423\n",
      "Iteration 28: Loss = 0.47228813381256723\n",
      "Iteration 29: Loss = 0.4646612360020009\n",
      "Iteration 30: Loss = 0.45707121227395453\n",
      "Iteration 31: Loss = 0.4495177830555849\n",
      "Iteration 32: Loss = 0.44200066846140657\n",
      "Iteration 33: Loss = 0.43451958839099075\n",
      "Iteration 34: Loss = 0.427074262624255\n",
      "Iteration 35: Loss = 0.4196644109143209\n",
      "Iteration 36: Loss = 0.41228975307791954\n",
      "Iteration 37: Loss = 0.4049500090833329\n",
      "Iteration 38: Loss = 0.3976448991358594\n",
      "Iteration 39: Loss = 0.39037414376079915\n",
      "Iteration 40: Loss = 0.38313746388395936\n",
      "Iteration 41: Loss = 0.37593458090967763\n",
      "Iteration 42: Loss = 0.36876521679637353\n",
      "Iteration 43: Loss = 0.3616290941296374\n",
      "Iteration 44: Loss = 0.354525936192866\n",
      "Iteration 45: Loss = 0.3474554670354655\n",
      "Iteration 46: Loss = 0.3404174115386369\n",
      "Iteration 47: Loss = 0.3334114954787685\n",
      "Iteration 48: Loss = 0.32643744558845667\n",
      "Iteration 49: Loss = 0.3194949896151839\n",
      "Iteration 50: Loss = 0.3125838563776825\n",
      "Iteration 51: Loss = 0.305703775820013\n",
      "Iteration 52: Loss = 0.29885447906339274\n",
      "Iteration 53: Loss = 0.29203569845580696\n",
      "Iteration 54: Loss = 0.28524716761943936\n",
      "Iteration 55: Loss = 0.27848862149595977\n",
      "Iteration 56: Loss = 0.2717597963897073\n",
      "Iteration 57: Loss = 0.2650604300088087\n",
      "Iteration 58: Loss = 0.2583902615042738\n",
      "Iteration 59: Loss = 0.25174903150710837\n",
      "Iteration 60: Loss = 0.2451364821634885\n",
      "Iteration 61: Loss = 0.238552357168038\n",
      "Iteration 62: Loss = 0.2319964017952546\n",
      "Iteration 63: Loss = 0.22546836292912648\n",
      "Iteration 64: Loss = 0.21896798909098636\n",
      "Iteration 65: Loss = 0.21249503046564538\n",
      "Iteration 66: Loss = 0.20604923892585275\n",
      "Iteration 67: Loss = 0.19963036805512607\n",
      "Iteration 68: Loss = 0.19323817316899652\n",
      "Iteration 69: Loss = 0.18687241133471394\n",
      "Iteration 70: Loss = 0.18053284138945555\n",
      "Iteration 71: Loss = 0.17421922395708425\n",
      "Iteration 72: Loss = 0.16793132146349793\n",
      "Iteration 73: Loss = 0.16166889815061553\n",
      "Iteration 74: Loss = 0.1554317200890413\n",
      "Iteration 75: Loss = 0.14921955518945113\n",
      "Iteration 76: Loss = 0.1430321732127417\n",
      "Iteration 77: Loss = 0.1368693457789859\n",
      "Iteration 78: Loss = 0.1307308463752328\n",
      "Iteration 79: Loss = 0.12461645036219553\n",
      "Iteration 80: Loss = 0.1185259349798636\n",
      "Iteration 81: Loss = 0.11245907935208176\n",
      "Iteration 82: Loss = 0.10641566449013065\n",
      "Iteration 83: Loss = 0.10039547329534926\n",
      "Iteration 84: Loss = 0.09439829056083424\n",
      "Iteration 85: Loss = 0.08842390297225328\n",
      "Iteration 86: Loss = 0.08247209910780691\n",
      "Iteration 87: Loss = 0.07654266943737383\n",
      "Iteration 88: Loss = 0.07063540632087306\n",
      "Iteration 89: Loss = 0.06475010400587608\n",
      "Iteration 90: Loss = 0.05888655862450074\n",
      "Iteration 91: Loss = 0.05304456818961851\n",
      "Iteration 92: Loss = 0.04722393259040537\n",
      "Iteration 93: Loss = 0.041424453587266076\n",
      "Iteration 94: Loss = 0.03564593480616062\n",
      "Iteration 95: Loss = 0.029888181732361095\n",
      "Iteration 96: Loss = 0.02415100170366621\n",
      "Iteration 97: Loss = 0.018434203903099775\n",
      "Iteration 98: Loss = 0.012737599351119257\n",
      "Iteration 99: Loss = 0.007061000897359083\n",
      "Iteration 100: Loss = 0.001404223211933021\n",
      "Final theta:\n",
      "[[-0.44628617]\n",
      " [-0.46412764]\n",
      " [ 0.50530387]\n",
      " [ 0.15921832]]\n"
     ]
    }
   ],
   "source": [
    "theta, loss_history = fit(X, Y_normalized)  # calculating theta and loss of each iteration\n",
    "\n",
    "# Print loss for each iteration\n",
    "for i, loss in enumerate(loss_history):\n",
    "    print(f\"Iteration {i + 1}: Loss = {loss}\")\n",
    "\n",
    "# Print final theta\n",
    "print(\"Final theta:\")\n",
    "print(theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b3fab6",
   "metadata": {},
   "source": [
    "### Testing Your Implementation\n",
    "To test your logistic regression implementation, first you should use `train_test_split` function to split dataset into three parts:\n",
    "\n",
    "- 70% for the training set\n",
    "- 20% for the validation set\n",
    "- 10% for the test set\n",
    "\n",
    "Do this in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4518fe11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shapes: (7002, 4) (7002, 1)\n",
      "Validation set shapes: (1998, 4) (1998, 1)\n",
      "Test set shapes: (1000, 4) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training, validation, and test sets\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y_normalized, test_size=0.1, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.222, random_state=42)  # 20% validation, 80% of 90% is 72%\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Training set shapes:\", X_train.shape, Y_train.shape)\n",
    "print(\"Validation set shapes:\", X_val.shape, Y_val.shape)\n",
    "print(\"Test set shapes:\", X_test.shape, Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fbe5d7",
   "metadata": {},
   "source": [
    "Then, you should complete `predict` function to find the weight vector and the loss on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95c2fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    '''\n",
    "    Use the model to predict values for each instance in X\n",
    "    Arguments:\n",
    "        theta is d-dimensional numpy vector\n",
    "        X     is a n-by-d numpy matrix\n",
    "    Returns:\n",
    "        an n-dimensional numpy vector of the predictions, the output should be binary (use h_theta > .5)\n",
    "    '''\n",
    "    h_theta = sigmoid(np.dot(X, theta))\n",
    "    Y = (h_theta > 0.5).astype(int)\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d1c02",
   "metadata": {},
   "source": [
    "Now, run the `fit` and `predict` function for different values of the learning rate and regularization constant. Plot the `loss_history` of these different values for train and test data both in the same figure.\n",
    "\n",
    "**Question**: Discuss the effect of the learning rate and regularization constant and find the best values of these parameters.\n",
    "\n",
    "**Answer**: \n",
    "\n",
    "Effect of Learning Rate:\n",
    "Too Small: If the learning rate is too small, the model may take a long time to converge, or it may get stuck in local minima.\n",
    "Too Large: On the other hand, if the learning rate is too large, the model may overshoot the minimum and fail to converge or diverge.\n",
    "Best Value: The best learning rate is often found through experimentation. It should be large enough to converge quickly but small enough to avoid oscillations or divergence.\n",
    "\n",
    "\n",
    "Effect of Regularization Constant:\n",
    "Too Small (Weak Regularization): If the regularization constant is too small, the model may overfit the training data, resulting in poor generalization to unseen data.\n",
    "Too Large (Strong Regularization): Conversely, if the regularization constant is too large, the model may underfit the training data, leading to high bias and low variance but potentially sacrificing too much predictive power.\n",
    "Best Value: Similar to the learning rate, the best regularization constant is often found through experimentation. It should strike a balance between preventing overfitting and preserving model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd2af382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define ranges for learning rate and regularization constant\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "reg_lambdas = [0.001, 0.01, 0.1]\n",
    "\n",
    "# Initialize lists to store loss histories\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Iterate over all combinations of learning rates and regularization constants\n",
    "for alpha in learning_rates:\n",
    "    for regLambda in reg_lambdas:\n",
    "        # Train the model using the fit function\n",
    "        theta, loss_history = fit(X_train, Y_train, regLambda=regLambda, alpha=alpha)\n",
    "        \n",
    "        # Compute loss on train and test data\n",
    "        train_loss = computeCost(theta, X_train, Y_train, regLambda)\n",
    "        test_loss = computeCost(theta, X_test, Y_test, regLambda)\n",
    "        \n",
    "        # Append loss histories\n",
    "        train_losses.append(loss_history)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "# Plot loss histories\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, (alpha, regLambda) in enumerate(zip(learning_rates, reg_lambdas)):\n",
    "    plt.plot(train_losses[i], label=f\"Train (alpha={alpha}, regLambda={regLambda})\")\n",
    "    plt.plot(test_losses[i], label=f\"Test (alpha={alpha}, regLambda={regLambda})\", linestyle='--')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss History for Different Learning Rates and Regularization Constants')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11babf15",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "In this part, you will use the `GaussianNB` classifier to classify the data. You should not change the default parameters of this classifier. First, train the classifier on the training set and then find the accuracy of it on the test set.\n",
    "\n",
    "**Question**: What is the accuracy of this method on test set?\n",
    "\n",
    "**Answer**: 0.957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ef450fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gaussian Naive Bayes on test set: 0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Digi Max\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Binarize the labels (convert to 0 or 1)\n",
    "Y_train_binary = (Y_train > 0).astype(int)\n",
    "Y_test_binary = (Y_test > 0).astype(int)\n",
    "\n",
    "# Train the Gaussian Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, Y_train_binary)\n",
    "\n",
    "# Predict labels for the test set\n",
    "Y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test_binary, Y_pred)\n",
    "print(\"Accuracy of Gaussian Naive Bayes on test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b371657d",
   "metadata": {},
   "source": [
    "## LDA (Linear Discriminant Analysis)\n",
    "\n",
    "In this part, you will use the `LinearDiscriminantAnalysis` classifier to classify the data. You should not change the default parameters of this classifier. First, train the classifier on the training set and then find the accuracy of it on the test set.\n",
    "\n",
    "**Question**: What is the accuracy of this method on test set?\n",
    "\n",
    "**Answer**: 0.987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92cc8743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Linear Discriminant Analysis on test set: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Digi Max\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Binarize the labels (convert to 0 or 1)\n",
    "Y_train_binary = (Y_train > 0).astype(int)\n",
    "Y_test_binary = (Y_test > 0).astype(int)\n",
    "\n",
    "# Train the Linear Discriminant Analysis (LDA) classifier\n",
    "lda_classifier = LinearDiscriminantAnalysis()\n",
    "lda_classifier.fit(X_train, Y_train_binary)\n",
    "\n",
    "# Predict labels for the test set\n",
    "Y_pred = lda_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test_binary, Y_pred)\n",
    "print(\"Accuracy of Linear Discriminant Analysis on test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47736bdf",
   "metadata": {},
   "source": [
    "## Conclution\n",
    "\n",
    "**Question**: What is the best method for classifying this dataset? What is the best accuracy on the test set?\n",
    "\n",
    "**Answer**: Since LDA had the best performance on this dataset so LDA is the best method for classifying this dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

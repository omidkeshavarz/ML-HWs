{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1b46fe41",
      "metadata": {
        "id": "1b46fe41"
      },
      "source": [
        "<h1 align=\"center\">Introduction to Machine Learning - Course Code: 25737</h1>\n",
        "<h4 align=\"center\">Instructor: Dr. Amiri</h4>\n",
        "<h4 align=\"center\">Sharif University of Technology, Spring 2024</h4>\n",
        "<h4 align=\"center\">Computer Assignment 3</h4>\n",
        "<h4 align=\"center\">\n",
        "\n",
        "Question 1\n",
        "\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24a0fc13",
      "metadata": {
        "id": "24a0fc13"
      },
      "source": [
        "# Personal Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44babb65",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "44babb65"
      },
      "outputs": [],
      "source": [
        "# Set your student number\n",
        "student_number = 99102072\n",
        "Name = 'Omid'\n",
        "Last_Name = 'Keshavarz'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca4a337a",
      "metadata": {
        "id": "ca4a337a"
      },
      "source": [
        "# Rules\n",
        "- You are not allowed to add or remove cells. You **must use the provided space to write your code**. If you don't follow this rule, **your Practical Assignment won't be graded**.  \n",
        "\n",
        "- Collaboration and using the internet is allowed, but your code **must be written by yourself**. **Copying code** from each other or from available resources will result in a **zero score for the assignment**.\n",
        "\n",
        "- You are not allowed to use `torch.nn`, `torch.optim` and any activation function and loss function implemented in torch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12b76789",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12b76789",
        "outputId": "2f573bdf-0810-4b21-a636-b34db11cf53c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.3.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install torchvision\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "886188c7",
      "metadata": {
        "id": "886188c7"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a0adcc",
      "metadata": {
        "id": "55a0adcc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18510868",
      "metadata": {
        "id": "18510868"
      },
      "source": [
        "## Datasets and Dataloaders\n",
        "\n",
        "Here, we download and load the train and test `FashionMNIST` dataset with the desired transforms. Then, we define the dataloaders for `train` and `test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc8759e2",
      "metadata": {
        "id": "dc8759e2"
      },
      "outputs": [],
      "source": [
        "train_set = FashionMNIST(root='.', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_set = FashionMNIST(root='.', train=False, download=True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df47fcb",
      "metadata": {
        "id": "5df47fcb"
      },
      "source": [
        "\n",
        "Here you have to calculate the number of classes amd input dimention of the first layer (how many pixels does each image have?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "8f6763e6",
      "metadata": {
        "id": "8f6763e6"
      },
      "outputs": [],
      "source": [
        "## FILL HERE\n",
        "#Set the input dim to number of pixels of fashionMnist pictures\n",
        "input_dim = 784\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "c695ff60",
      "metadata": {
        "id": "c695ff60"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, 64, shuffle=True)\n",
        "test_loader = DataLoader(test_set, 64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9dac6c2",
      "metadata": {
        "id": "f9dac6c2"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "Visualize 1 random image from each class by using `plt.subplots`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3d6b0c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "e3d6b0c1",
        "outputId": "72260917-45c9-4017-ad90-6bc605117845"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x300 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#visualize 1 random image from each class of FashionMNIST by using plt.subplots\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Define class names\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# Find a random image for each class\n",
        "num_classes = len(class_names)\n",
        "fig, axes = plt.subplots(1, num_classes, figsize=(15, 3))\n",
        "\n",
        "for i in range(num_classes):\n",
        "  # Filter images for the current class\n",
        "  class_indices = np.where(train_labels == i)[0]\n",
        "  random_index = np.random.choice(class_indices)\n",
        "  image = train_images[random_index]\n",
        "\n",
        "  # Display the image\n",
        "  axes[i].imshow(image, cmap='gray')\n",
        "  axes[i].set_title(class_names[i])\n",
        "  axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a94c5aba",
      "metadata": {
        "id": "a94c5aba"
      },
      "source": [
        "## Initializing model's parameters\n",
        "\n",
        "In this part, we create the model and initialize its parameters and store the values of these parameters in the variable `parameters` which is a dictionary including the weigths and biases of each layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "e6d40952",
      "metadata": {
        "id": "e6d40952"
      },
      "outputs": [],
      "source": [
        "def add_linear_layer(parameters, shape, device, layer_idx):\n",
        "    w_key = f'w{layer_idx+1}'\n",
        "    b_key = f'b{layer_idx+1}'\n",
        "    parameters[w_key] = torch.randn(shape[0], shape[1], requires_grad=True, device=device) * 0.01\n",
        "    parameters[b_key] = torch.zeros(shape[1], requires_grad=True, device=device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce914706",
      "metadata": {
        "id": "ce914706"
      },
      "source": [
        "Now we define our neural network with the given layers and add the weights and biases to the dictionary `parameters`. **You are allowed to modify the values of the layers**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "8f3867d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f3867d7",
        "outputId": "73e53aa1-7132-4378-b4ed-6a3258334b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['w1', 'b1', 'w2', 'b2', 'w3', 'b3', 'w4', 'b4', 'w5', 'b5'])\n"
          ]
        }
      ],
      "source": [
        "layers = [\n",
        "    (input_dim, 512),\n",
        "    (512, 256),\n",
        "    (256, 128),\n",
        "    (128, 64),\n",
        "    (64, num_classes)\n",
        "]\n",
        "num_layers = len(layers)\n",
        "parameters = {}\n",
        "\n",
        "# Setting the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Adding the parameters to the dictionary\n",
        "for i, shape in enumerate(layers):\n",
        "    add_linear_layer(parameters, shape, device, i)\n",
        "\n",
        "# Check the keys in parameters to verify\n",
        "print(parameters.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bfd2c8e",
      "metadata": {
        "id": "8bfd2c8e"
      },
      "source": [
        "## Defining the required functions\n",
        "\n",
        "In this section, we should define the required functions. For each of these functions, the inputs and the desired outputs are given and you should write all or part of the function. **You are not allowed to use the activation functions and the loss functions implemented in torch**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b413d8",
      "metadata": {
        "id": "f3b413d8"
      },
      "source": [
        "Computing affine and relu outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "bebeeb0e",
      "metadata": {
        "id": "bebeeb0e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming device is set\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def affine_forward(x, w, b):\n",
        "    N = x.shape[0]  # batch size\n",
        "    x_reshaped = x.view(N, -1)  # Flatten the input if necessary\n",
        "    out = x_reshaped @ w + b\n",
        "    cache = (x, w, b)\n",
        "    return out, cache\n",
        "\n",
        "\n",
        "def relu(x):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a layer of rectified linear units (ReLUs).\n",
        "\n",
        "    Input:\n",
        "    - x: Inputs, of any shape\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: Output, of the same shape as x\n",
        "    - cache: x\n",
        "    \"\"\"\n",
        "    out = torch.maximum(torch.tensor(0, dtype=x.dtype), x)\n",
        "    cache = x\n",
        "    return out, cache\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d9baa5e",
      "metadata": {
        "id": "5d9baa5e"
      },
      "source": [
        "Function `model` returns output of the whole model for the input `x` using the parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "d2562962",
      "metadata": {
        "id": "d2562962"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def model(x: torch.Tensor, parameters, num_layers):\n",
        "    \"\"\"\n",
        "    Implements a neural network with multiple layers.\n",
        "\n",
        "    Inputs:\n",
        "    - x: Input tensor of shape (B, D_in), where B is the batch size and D_in is the input dimension.\n",
        "    - parameters: A dictionary containing the weights and biases for each layer.\n",
        "    - num_layers: The number of layers in the neural network.\n",
        "\n",
        "    Returns:\n",
        "    - output: The output tensor of the network.\n",
        "    \"\"\"\n",
        "    # Number of batches\n",
        "    B = x.shape[0]\n",
        "    x = x.view(B, -1)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        w = parameters[f'w{i+1}']\n",
        "        b = parameters[f'b{i+1}']\n",
        "\n",
        "        x, _ = affine_forward(x, w, b)\n",
        "\n",
        "        if i < num_layers - 1:  # Apply ReLU activation to all layers except the last one\n",
        "            x, _ = relu(x)\n",
        "\n",
        "    output = x\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d17a9b4c",
      "metadata": {
        "id": "d17a9b4c"
      },
      "source": [
        "Implementing cross entropy loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "6959621c",
      "metadata": {
        "id": "6959621c"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_loss(scores, y):\n",
        "    \"\"\"\n",
        "    Computes the loss and gradient for softmax classification.\n",
        "\n",
        "    Inputs:\n",
        "    - scores: Input data, of shape (N, C) where scores[i, j] is the score for the j-th class\n",
        "      for the i-th input.\n",
        "    - y: Vector of labels, of shape (N,) where y[i] is the label for scores[i] and 0 <= y[i] < C\n",
        "\n",
        "    Returns a tensor giving the loss.\n",
        "    \"\"\"\n",
        "    # Number of samples\n",
        "    N = scores.shape[0]\n",
        "\n",
        "    # Shift the scores for numerical stability\n",
        "    shifted_scores = scores - torch.max(scores, dim=1, keepdim=True).values\n",
        "\n",
        "    # Compute the class probabilities\n",
        "    exp_scores = torch.exp(shifted_scores)\n",
        "    probs = exp_scores / torch.sum(exp_scores, dim=1, keepdim=True)\n",
        "\n",
        "    # Compute the loss\n",
        "    correct_logprobs = -torch.log(probs[torch.arange(N), y])\n",
        "    loss = torch.sum(correct_logprobs) / N\n",
        "\n",
        "    return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15a589af",
      "metadata": {
        "id": "15a589af"
      },
      "source": [
        "Implementing a function for optimizing paramters and a function to zeroing out their gradients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "3121c147",
      "metadata": {
        "id": "3121c147"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from typing import Dict\n",
        "\n",
        "def sgd_optimizer(parameters, learning_rate):\n",
        "    with torch.no_grad():\n",
        "        for param in parameters.values():\n",
        "            if param.grad is not None:\n",
        "                param -= learning_rate * param.grad\n",
        "                param.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17b4cf8",
      "metadata": {
        "id": "e17b4cf8"
      },
      "source": [
        "Training functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "76c0f03b",
      "metadata": {
        "id": "76c0f03b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def accuracy(y_pred: np.ndarray, y_true: np.ndarray):\n",
        "    \"\"\"\n",
        "    Computes the accuracy of predictions.\n",
        "\n",
        "    Inputs:\n",
        "    - y_pred: A numpy array of predicted labels\n",
        "    - y_true: A numpy array of true labels\n",
        "\n",
        "    Returns:\n",
        "    - acc: The accuracy as a float\n",
        "    \"\"\"\n",
        "    acc = np.mean(y_pred == y_true)\n",
        "    return acc\n",
        "\n",
        "def train(train_loader, parameters, learning_rate=0.001, epoch=None):\n",
        "    train_loss = 0\n",
        "    N_train = len(train_loader.dataset)\n",
        "    Y = []\n",
        "    Y_pred = []\n",
        "\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        p = model(x, parameters, num_layers)\n",
        "\n",
        "        loss = cross_entropy_loss(p, y)\n",
        "        loss.backward()\n",
        "\n",
        "        sgd_optimizer(parameters, learning_rate)\n",
        "\n",
        "        # Clear the gradients after updating the parameters\n",
        "        for param in parameters.values():\n",
        "            if param.grad is not None:\n",
        "                param.grad.zero_()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        y_pred = p.argmax(dim=-1)\n",
        "        Y.append(y.cpu().numpy())\n",
        "        Y_pred.append(y_pred.cpu().numpy())\n",
        "\n",
        "    Y = np.concatenate(Y)\n",
        "    Y_pred = np.concatenate(Y_pred)\n",
        "    acc = accuracy(torch.tensor(Y_pred), torch.tensor(Y))\n",
        "    print(f'Epoch {epoch}, Train Loss: {train_loss / len(train_loader)}, Train Accuracy: {acc}')\n",
        "    return train_loss / len(train_loader), acc\n",
        "\n",
        "\n",
        "def validate(loader, epoch=None, set_name=None):\n",
        "    '''\n",
        "    Validates the model on the given data loader.\n",
        "\n",
        "    Inputs:\n",
        "    - loader: DataLoader for validation/test data\n",
        "    - epoch: Current epoch number\n",
        "    - set_name: Name of the dataset (e.g., 'Validation', 'Test')\n",
        "\n",
        "    Returns:\n",
        "    - total_loss: The average loss over the dataset\n",
        "    - acc: The accuracy over the dataset\n",
        "    '''\n",
        "    total_loss = 0\n",
        "    N = len(loader.dataset)\n",
        "\n",
        "    # Creating empty lists Y and Y_pred to store the labels and predictions of each batch\n",
        "    Y = []\n",
        "    Y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(loader):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            p = model(x, parameters)\n",
        "\n",
        "            # Compute loss\n",
        "            loss, _ = cross_entropy_loss(p, y)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Store predictions and true labels\n",
        "            y_pred = p.argmax(dim=-1)\n",
        "            Y.append(y.cpu().numpy())\n",
        "            Y_pred.append(y_pred.cpu().numpy())\n",
        "\n",
        "            print(f'Epoch [{epoch}], Batch [{i}], Loss: {loss.item()}')\n",
        "\n",
        "    total_loss /= len(loader)\n",
        "    Y = np.concatenate(Y)\n",
        "    Y_pred = np.concatenate(Y_pred)\n",
        "    acc = accuracy(Y_pred, Y)\n",
        "    print(f'Accuracy of {set_name} set: {acc}')\n",
        "\n",
        "    return total_loss, acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ebb4b6",
      "metadata": {
        "id": "87ebb4b6"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d4eb0b",
      "metadata": {
        "id": "28d4eb0b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_model(dataloaders, num_epochs, parameters, learning_rate=0.001, model_name='pytorch_model'):\n",
        "    '''This function trains the model for the number of epochs given and stores, calculates and prints the train\n",
        "    and test losses and accuracies. Finally, it plots the accuracy and loss history for training and test sets'''\n",
        "    train_loader, test_loader = dataloaders\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        train_loss, train_acc = train(train_loader, parameters, learning_rate, epoch)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        # Validation phase\n",
        "        test_loss, test_acc = validate(test_loader, parameters, epoch, 'Test')\n",
        "        test_losses.append(test_loss)\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "    # Plot the loss history of training and test sets\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
        "    plt.plot(range(1, num_epochs+1), test_losses, label='Test Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss History')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot the accuracy history of training and test sets\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(1, num_epochs+1), train_accuracies, label='Train Accuracy')\n",
        "    plt.plot(range(1, num_epochs+1), test_accuracies, label='Test Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy History')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "2ec4bdd2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "2ec4bdd2",
        "outputId": "1e190fac-d489-4dd8-9877-3b9cc1b7901d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "----------\n",
            "torch.Size([64, 784])\n",
            "torch.Size([784, 512])\n",
            "torch.Size([64, 512])\n",
            "torch.Size([512, 256])\n",
            "torch.Size([64, 256])\n",
            "torch.Size([256, 128])\n",
            "torch.Size([64, 128])\n",
            "torch.Size([128, 64])\n",
            "torch.Size([64, 64])\n",
            "torch.Size([64, 10])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-3a444eec8b3b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-51-365d925affab>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(dataloaders, num_epochs, parameters, learning_rate, model_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-9ea6365a65da>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, parameters, learning_rate, epoch)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0msgd_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ],
      "source": [
        "train_model([train_loader, test_loader], num_epochs=25, parameters=parameters, learning_rate=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceb5783f",
      "metadata": {
        "id": "ceb5783f"
      },
      "outputs": [],
      "source": [
        "print(f'Final test accuracy: {test_accuracies[-1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5e128ed",
      "metadata": {
        "id": "a5e128ed"
      },
      "source": [
        "## Visualization of the labels and predictions\n",
        "\n",
        "In this section, you should visual one image from each class and show both the actual label and the predicted label for that image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c0b79fd",
      "metadata": {
        "id": "6c0b79fd"
      },
      "outputs": [],
      "source": [
        "## FILL HERE"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}